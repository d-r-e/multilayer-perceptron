{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/17 [00:00<?, ?it/s]/Users/darodrig/Desktop/multilayer-perceptron/src/ft_math.py:38: RuntimeWarning: divide by zero encountered in log\n",
      "  log_likelihood = -np.log(p[range(m),y])\n",
      "/Users/darodrig/Desktop/multilayer-perceptron/src/ft_math.py:11: RuntimeWarning: invalid value encountered in subtract\n",
      "  exps = np.exp(X - np.max(X))\n",
      "100%|██████████| 17/17 [00:00<00:00, 3019.02it/s]\n",
      "100%|██████████| 17/17 [00:00<00:00, 3711.58it/s]\n",
      "100%|██████████| 17/17 [00:00<00:00, 3499.54it/s]\n",
      "100%|██████████| 17/17 [00:00<00:00, 3581.99it/s]\n",
      "100%|██████████| 17/17 [00:00<00:00, 3721.65it/s]\n",
      "100%|██████████| 17/17 [00:00<00:00, 3807.30it/s]\n",
      "100%|██████████| 17/17 [00:00<00:00, 3830.62it/s]\n",
      "100%|██████████| 17/17 [00:00<00:00, 3888.06it/s]\n",
      "100%|██████████| 17/17 [00:00<00:00, 4203.70it/s]\n",
      "100%|██████████| 17/17 [00:00<00:00, 4232.14it/s]\n",
      "100%|██████████| 17/17 [00:00<00:00, 3672.39it/s]\n",
      "100%|██████████| 17/17 [00:00<00:00, 3528.64it/s]\n",
      "100%|██████████| 17/17 [00:00<00:00, 3725.35it/s]\n",
      "100%|██████████| 17/17 [00:00<00:00, 3983.19it/s]\n",
      "100%|██████████| 17/17 [00:00<00:00, 4208.66it/s]\n",
      "100%|██████████| 17/17 [00:00<00:00, 3705.22it/s]\n",
      "100%|██████████| 17/17 [00:00<00:00, 4118.24it/s]\n",
      "100%|██████████| 17/17 [00:00<00:00, 3691.60it/s]\n",
      "100%|██████████| 17/17 [00:00<00:00, 3823.64it/s]\n",
      "100%|██████████| 17/17 [00:00<00:00, 3986.98it/s]\n",
      "100%|██████████| 17/17 [00:00<00:00, 4166.61it/s]\n",
      "100%|██████████| 17/17 [00:00<00:00, 4202.71it/s]\n",
      "100%|██████████| 17/17 [00:00<00:00, 3937.88it/s]\n",
      "100%|██████████| 17/17 [00:00<00:00, 4116.10it/s]\n",
      "100%|██████████| 17/17 [00:00<00:00, 3810.76it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import normalize\n",
    "from src.ft_math import mean, softmax, sigmoid, cross_entropy, delta_cross_entropy\n",
    "from src.Perceptron import Dense, Relu, softmax_crossentropy_with_logits, grad_softmax_crossentropy_with_logits\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df = pd.read_csv('./data/data.csv')\n",
    "    X_train = np.array(df.iloc[:,2:])\n",
    "    y_train = np.squeeze(np.array(df['diagnosis'].map({'M':1,'B':0})))\n",
    "\n",
    "    network = []\n",
    "    network.append(Dense(X_train.shape[1], 20))\n",
    "    network.append(Relu())\n",
    "    network.append(Dense(20, 10))\n",
    "    network.append(Relu())\n",
    "    network.append(Dense(10, 2))\n",
    "\n",
    "    def forward(network, X):\n",
    "    # Compute activations of all network layers by applying them sequentially.\n",
    "    # Return a list of activations for each layer. \n",
    "    \n",
    "        activations = []\n",
    "        input = X\n",
    "        # Looping through each layer\n",
    "        for l in network:\n",
    "            activations.append(l.forward(input))\n",
    "            # Updating input to last layer output\n",
    "            input = activations[-1]\n",
    "        \n",
    "        assert len(activations) == len(network)\n",
    "        return activations\n",
    "        \n",
    "    def predict(network,X):\n",
    "        # Compute network predictions. Returning indices of largest Logit probability\n",
    "        logits = forward(network,X)[-1]\n",
    "        return logits.argmax(axis=-1)\n",
    "\n",
    "    def train(network,X,y):\n",
    "        # Train our network on a given batch of X and y.\n",
    "        # We first need to run forward to get all layer activations.\n",
    "        # Then we can run layer.backward going from last to first layer.\n",
    "        # After we have called backward for all layers, all Dense layers have already made one gradient step.\n",
    "        \n",
    "        \n",
    "        # Get the layer activations\n",
    "        layer_activations = forward(network,X)\n",
    "        layer_inputs = [X]+layer_activations  #layer_input[i] is an input for network[i]\n",
    "        logits = layer_activations[-1]\n",
    "        \n",
    "        # Compute the loss and the initial gradient\n",
    "        loss = cross_entropy(logits,y)\n",
    "        loss_grad = delta_cross_entropy(logits,y)\n",
    "        \n",
    "        # Propagate gradients through the network\n",
    "        # Reverse propogation as this is backprop\n",
    "        for layer_index in range(len(network))[::-1]:\n",
    "            layer = network[layer_index]\n",
    "            \n",
    "            loss_grad = layer.backward(layer_inputs[layer_index],loss_grad) #grad w.r.t. input, also weight updates\n",
    "            \n",
    "        return np.mean(loss)\n",
    "\n",
    "    from tqdm import trange\n",
    "    def iterate_minibatches(inputs, targets, batchsize, shuffle=False):\n",
    "        assert len(inputs) == len(targets)\n",
    "        if shuffle:\n",
    "            indices = np.random.permutation(len(inputs))\n",
    "        for start_idx in trange(0, len(inputs) - batchsize + 1, batchsize):\n",
    "            if shuffle:\n",
    "                excerpt = indices[start_idx:start_idx + batchsize]\n",
    "            else:\n",
    "                excerpt = slice(start_idx, start_idx + batchsize)\n",
    "            yield inputs[excerpt], targets[excerpt]\n",
    "    from IPython.display import clear_output\n",
    "    train_log = []\n",
    "    val_log = []\n",
    "    for epoch in range(25):\n",
    "        for x_batch,y_batch in iterate_minibatches(X_train,y_train,batchsize=32,shuffle=True):\n",
    "            train(network,x_batch,y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
